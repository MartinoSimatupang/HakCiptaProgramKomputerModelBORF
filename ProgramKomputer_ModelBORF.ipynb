{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c61d3d6",
   "metadata": {},
   "source": [
    "# MODEL RANDOM FOREST DENGAN BAYESIAN OPTIMIZATION HYPERPARAMETER TUNING (BO-RF) UNTUK ANALISIS PERGERAKAN DAN PREDIKSI HARGA SAHAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6862bde",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e939fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Library yang dibutuhkan\n",
    "#%pip install TA-Lib\n",
    "#%pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069028e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# Grafik dan Visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# Indikator Teknikal Saham\n",
    "import talib\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, root_mean_squared_error, r2_score\n",
    "\n",
    "filterwarnings('ignore')\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774349e",
   "metadata": {},
   "source": [
    "## DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568c994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collection(path_data):\n",
    "    print('--- Proses Data Collection ---')    \n",
    "    # Memasukkan data olahan harga saham harian\n",
    "    try:\n",
    "        df = pd.read_excel(path_data, parse_dates=['Date'], index_col='Date')\n",
    "        print(f'Data berhasil dikoleksi dari {path_data}')\n",
    "    except Exception as e:\n",
    "        print(f'Error dalam koleksi data: {e}')\n",
    "        return None\n",
    "    \n",
    "    # Inspeksi data awal\n",
    "    print('Ukuran data:', df.shape)\n",
    "    print('Lima data teratas:')\n",
    "    display(df.head(5))\n",
    "    print('Informasi umum data:')\n",
    "    df.info()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8bfd1",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc59adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(df):\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df_awal):\n",
    "    df_fitur = pd.DataFrame(index=df_awal.index)\n",
    "    \n",
    "    df_fitur['Intraday_Range'] = df_awal['High'] - df_awal['Low'] \n",
    "    df_fitur['Intraday_Change'] = df_awal['Close'] - df_awal['Open'] \n",
    "    df_fitur['MA_5'] = talib.MA(df_awal['Close'], timeperiod=5) \n",
    "    df_fitur['MA_10'] = talib.MA(df_awal['Close'], timeperiod=10) \n",
    "    df_fitur['RSI_7'] = talib.RSI(df_awal['Close'], timeperiod=7) \n",
    "    df_fitur['RSI_14'] = talib.RSI(df_awal['Close'], timeperiod=14) \n",
    "    df_fitur['MOM_10'] = talib.MOM(df_awal['Close'], timeperiod=10) \n",
    "    df_fitur['ROC_10'] = talib.ROC(df_awal['Close'], timeperiod=10) \n",
    "    df_fitur['ATR_14'] = talib.ATR(df_awal['High'], df_awal['Low'], df_awal['Close'], timeperiod=14) \n",
    "    df_fitur['Volatility_10'] = df_awal['Close_Diff'].rolling(window=10).std() \n",
    "    \n",
    "    df_fitur['Open_t-1'] = df_awal['Open'].shift(1) \n",
    "    df_fitur['High_t-1'] = df_awal['High'].shift(1) \n",
    "    df_fitur['Low_t-1'] = df_awal['Low'].shift(1) \n",
    "    df_fitur['Close_t-1'] = df_awal['Close'].shift(1) \n",
    "    \n",
    "    if 'Volume_Log' in df_awal.columns:\n",
    "        df_fitur['Volume_Log_t-1'] = df_awal['Volume_Log'].shift(1)\n",
    "    \n",
    "    df_fitur['Close_Diff_t-1'] = df_awal['Close_Diff'].shift(1) \n",
    "    \n",
    "    df_fitur['Intraday_Range_t-1'] = df_fitur['Intraday_Range'].shift(1) \n",
    "    df_fitur['Intraday_Change_t-1'] = df_fitur['Intraday_Change'].shift(1) \n",
    "    df_fitur['MA_5_t-1'] = df_fitur['MA_5'].shift(1) \n",
    "    df_fitur['MA_10_t-1'] = df_fitur['MA_10'].shift(1) \n",
    "    df_fitur['RSI_7_t-1'] = df_fitur['RSI_7'].shift(1) \n",
    "    df_fitur['RSI_14_t-1'] = df_fitur['RSI_14'].shift(1) \n",
    "    df_fitur['MOM_10_t-1'] = df_fitur['MOM_10'].shift(1) \n",
    "    df_fitur['ROC_10_t-1'] = df_fitur['ROC_10'].shift(1) \n",
    "    df_fitur['ATR_14_t-1'] = df_fitur['ATR_14'].shift(1) \n",
    "    df_fitur['Volatility_10_t-1'] = df_fitur['Volatility_10'].shift(1) \n",
    "\n",
    "    df_fitur['Year'] = df_fitur.index.year \n",
    "    df_fitur['Month'] = df_fitur.index.month \n",
    "    df_fitur['Week'] = df_fitur.index.isocalendar().week.astype(float) \n",
    "    df_fitur['DayOfWeek'] = df_fitur.index.dayofweek \n",
    "    df_fitur['DayOfMonth'] = df_fitur.index.day \n",
    "    df_fitur['DayOfYear'] = df_fitur.index.dayofyear \n",
    "    df_fitur['Quarter'] = df_fitur.index.quarter \n",
    "    df_fitur['IsMonthStart'] = df_fitur.index.is_month_start.astype(int) \n",
    "    df_fitur['IsMonthEnd'] = df_fitur.index.is_month_end.astype(int) \n",
    "\n",
    "    df_fitur.dropna(inplace=True)\n",
    "    return df_fitur\n",
    "\n",
    "def data_preparation(df):\n",
    "    print('--- Proses Data Preparation ---')\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Data Cleaning & Data Transformation\n",
    "    if 'Volume' in df_prep.columns:\n",
    "        df_prep['Volume'] = df_prep['Volume'].ffill().fillna(0)\n",
    "        df_prep['Volume_Log'] = np.log1p(df_prep['Volume'])\n",
    "        df_prep = df_prep.drop('Volume', axis=1)\n",
    "        \n",
    "    df_prep['Close_Diff'] = df_prep['Close'].diff()\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df_fitur = feature_engineering(df_prep)\n",
    "    \n",
    "    # Data Augmentation\n",
    "    df_keseluruhan = pd.concat([df_prep, df_fitur], axis=1)\n",
    "    df_keseluruhan.dropna(inplace=True)\n",
    "    df_keseluruhan = data_augmentation(df_keseluruhan)\n",
    "\n",
    "    # Feature Selection & Data Splitting\n",
    "    variabel_input = [col for col in df_keseluruhan.columns if col not in['Open', 'High', 'Low', 'Volume_Log', 'Close', 'Close_Diff',\n",
    "                                                                  'Intraday_Range', 'Intraday_Change', 'MA_5', 'MA_10', 'RSI_7',\n",
    "                                                                  'RSI_14', 'MOM_10', 'ROC_10', 'ATR_14', 'Volatility_10',\n",
    "                                                                  'Open_t-1', 'High_t-1', 'Low_t-1', 'RSI_14_t-1', 'MA_10_t-1',\n",
    "                                                                  'ROC_10_t-1']]\n",
    "    \n",
    "    X = df_keseluruhan[variabel_input]\n",
    "    y = df_keseluruhan['Close_Diff']\n",
    "    \n",
    "    train_size = int(len(df_keseluruhan) * 0.8)\n",
    "    X_train = X.iloc[:train_size]\n",
    "    X_test = X.iloc[train_size:]\n",
    "    y_train = y.iloc[:train_size]\n",
    "    y_test = y.iloc[train_size:]\n",
    "\n",
    "    print(f'Dimensi X_train: {X_train.shape}')\n",
    "    print(f'Dimensi X_test: {X_test.shape}')\n",
    "    print(f'Dimensi y_train: {y_train.shape}')\n",
    "    print(f'Dimensi y_test: {y_test.shape}')\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, df_keseluruhan, variabel_input  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57432eba",
   "metadata": {},
   "source": [
    "## MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6637854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_development(X_train, y_train):\n",
    "    print('--- Proses Model Development ---')\n",
    "    \n",
    "    pbounds = {'n_estimators': (200, 1000),\n",
    "               'max_depth': (5, 50),\n",
    "               'min_samples_leaf': (1, 15),\n",
    "               'min_samples_split': (2, 20),\n",
    "               'max_features': (0.1, 1.0)}\n",
    "\n",
    "    def rf_cv_score(n_estimators, max_depth, min_samples_leaf, max_features, min_samples_split):\n",
    "        try:\n",
    "            n_estimators = int(n_estimators)\n",
    "            max_depth = int(max_depth)\n",
    "            min_samples_leaf = int(min_samples_leaf)\n",
    "            min_samples_split = int(min_samples_split)\n",
    "\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          max_features=max_features,\n",
    "                                          min_samples_split=min_samples_split,\n",
    "                                          random_state=42,\n",
    "                                          n_jobs=1)\n",
    "            \n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "            return np.mean(scores)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return -1e9 \n",
    "\n",
    "    optimizer = BayesianOptimization(f=rf_cv_score, pbounds=pbounds, random_state=42, verbose=2)\n",
    "    optimizer.maximize(init_points=5, n_iter=50)\n",
    "\n",
    "    best_params = optimizer.max['params']\n",
    "    best_params_formatted = {'n_estimators': int(best_params['n_estimators']),\n",
    "                             'max_depth': int(best_params['max_depth']),\n",
    "                             'min_samples_leaf': int(best_params['min_samples_leaf']),\n",
    "                             'min_samples_split': int(best_params['min_samples_split']),\n",
    "                             'max_features': best_params['max_features']}\n",
    "\n",
    "    print(f'Best Hyperparameters: {best_params_formatted}')\n",
    "\n",
    "    best_rf_model = RandomForestRegressor(**best_params_formatted, random_state=42, n_jobs=1)\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    return best_rf_model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e882e",
   "metadata": {},
   "source": [
    "## MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc3af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_test, y_test):\n",
    "    print('--- Proses Model Evaluation ---')\n",
    "    \n",
    "    y_pred_arr = model.predict(X_test)\n",
    "    y_pred = pd.Series(y_pred_arr, index=X_test.index, name='Pred_Close_Diff')\n",
    "    \n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print('RMSE:', rmse)\n",
    "    print('MAE:', mae)\n",
    "    print('R-squared:', r2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(y_test.index, y_test, label='Close_Diff Aktual', color='blue')\n",
    "    plt.plot(y_test.index, y_pred, label='Hasil Prediksi Close_Diff (BO-RF)', color='red', linestyle='--')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close_Diff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature Importance dalam Model BO-RF\n",
    "    importances = pd.Series(model.feature_importances_, index=variabel_input)\n",
    "    importances_sorted = importances.sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = sns.barplot(x=importances_sorted.values, y=importances_sorted.index, palette=\"viridis\")\n",
    "    for i, v in enumerate(importances_sorted.values):\n",
    "        ax.text(v + 0.001, i, f\"{v:.4f}\", color='black', va='center')\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a3770",
   "metadata": {},
   "source": [
    "## MODEL POSTPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ad3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_postprocessing(model, X_test, y_pred, df_keseluruhan, variabel_input):\n",
    "    print('--- Proses Model Post-Processing ---')\n",
    "     \n",
    "    # Inversi ke skala harga penutupan 'Close' \n",
    "    close_t_minus_1_test = df_keseluruhan.loc[X_test.index, 'Close_t-1']\n",
    "    close_actual_test = df_keseluruhan.loc[X_test.index, 'Close']\n",
    "    pred_close = close_t_minus_1_test + y_pred\n",
    "    \n",
    "    hasil_df = pd.DataFrame({'Close': close_actual_test,\n",
    "                             'Close_t-1': close_t_minus_1_test,\n",
    "                             'Pred_Close_Diff': y_pred,\n",
    "                             'Pred_Close': pred_close},\n",
    "                            index=X_test.index)\n",
    "    \n",
    "    # Metrik Evaluasi terhadap data terinversi\n",
    "    rmse_new = root_mean_squared_error(hasil_df['Close'], hasil_df['Pred_Close'])\n",
    "    mae_new = mean_absolute_error(hasil_df['Close'], hasil_df['Pred_Close'])\n",
    "    mape_new = mean_absolute_percentage_error(hasil_df['Close'], hasil_df['Pred_Close'])\n",
    "    r_squared_new = r2_score(hasil_df['Close'], hasil_df['Pred_Close'])\n",
    "    \n",
    "    print('RMSE (Terinversi):', rmse_new)\n",
    "    print('MAE (Terinversi):', mae_new)\n",
    "    print('MAPE (Terinversi):', mape_new)\n",
    "    print('R-squared (Terinversi):', r_squared_new)\n",
    "    \n",
    "    # Visualisasi data aktual dan data terinversi\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(hasil_df.index, hasil_df['Close'], label='Actual Close', color='blue')\n",
    "    plt.plot(hasil_df.index, hasil_df['Pred_Close'], label='Predicted Close (BO-RF)', color='red', linestyle='--')\n",
    "    plt.title(\"Actual vs Predicted Close Price\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    display(hasil_df.head(10))\n",
    "    return hasil_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b77d72",
   "metadata": {},
   "source": [
    "## MAIN FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a332a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lokasi penyimpanan file data harga saham harian\n",
    "path_data = r\"Masukkan Path Data Anda\"\n",
    "\n",
    "# Data Collection\n",
    "df_awal = data_collection(path_data)\n",
    "\n",
    "if df_awal is not None:\n",
    "    # Data Preparation\n",
    "    X_train, y_train, X_test, y_test, df_keseluruhan, variabel_input = data_preparation(df_awal)\n",
    "\n",
    "    # Model Development\n",
    "    best_model = model_development(X_train, y_train)\n",
    "\n",
    "    # Model Evaluation\n",
    "    y_pred_diff = model_evaluation(best_model, X_test, y_test)\n",
    "\n",
    "    # Model Postprocessing\n",
    "    df_results = model_postprocessing(best_model, X_test, y_pred_diff, df_keseluruhan, variabel_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
